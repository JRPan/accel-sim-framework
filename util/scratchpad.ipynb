{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse output.txt\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "file_path = \"/home/pan251/accel-sim-framework-pim/output.txt\"\n",
    "done_cycles = {}\n",
    "start_cycles = {}\n",
    "\n",
    "color_array = px.colors.qualitative.Plotly\n",
    "\n",
    "freq = 0\n",
    "last_done = 0\n",
    "\n",
    "xbar_to_layer = {}\n",
    "\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        match = re.match(r\"core (\\d*) xbar (\\d*) done layer, (\\d*)\", line)\n",
    "        if match:\n",
    "            core = int(match.group(1))\n",
    "            xbar_id = int(match.group(2))\n",
    "            cycle = int(match.group(3))\n",
    "            xbar_id = xbar_id + core * 256\n",
    "            if xbar_id not in done_cycles:\n",
    "                done_cycles[xbar_id] = []\n",
    "            done_cycles[xbar_id].append(cycle)\n",
    "            last_done = cycle\n",
    "\n",
    "        match = re.match(r\"core (\\d*) xbar (\\d*) start compute, (\\d*)\", line)\n",
    "        if match:\n",
    "            core = int(match.group(1))\n",
    "            xbar_id = int(match.group(2))\n",
    "            cycle = int(match.group(3))\n",
    "            xbar_id = xbar_id + core * 256\n",
    "            if xbar_id not in start_cycles:\n",
    "                start_cycles[xbar_id] = []\n",
    "            start_cycles[xbar_id].append(cycle)\n",
    "\n",
    "        match = re.match(r\"-gpgpu_clock_domains (\\d*.\\d*):.*\", line)\n",
    "        if match:\n",
    "            freq = float(match.group(1)) * 1e6\n",
    "\n",
    "        match = re.match(r\"layer (.*) mapped to core (\\d*) xbar (\\d*)\", line)\n",
    "        if match:\n",
    "            layer = match.group(1)\n",
    "            core = int(match.group(2))\n",
    "            xbar_id = int(match.group(3))\n",
    "            xbar_id = xbar_id + core * 256\n",
    "            xbar_to_layer[xbar_id] = \"layer \" + layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "to_plot = pd.DataFrame(columns=[\"layer\", \"xbar\", \"start\", \"done\", \"duration\", \"color\", \"text\"])\n",
    "for xbar, starts in start_cycles.items():\n",
    "    if xbar not in done_cycles:\n",
    "        continue\n",
    "    if (len(starts) != len(done_cycles[xbar])):\n",
    "        done_cycles[xbar].append(last_done)\n",
    "    assert(len(starts) == len(done_cycles[xbar]))\n",
    "    dones = done_cycles[xbar]\n",
    "    for index, start in enumerate(starts):\n",
    "        start = start\n",
    "        done = dones[index]\n",
    "        start = start / freq * 1e3\n",
    "        done = done / freq * 1e3\n",
    "        duration = (done - start)\n",
    "        # format\n",
    "        # duration = \"{:.5f}\".format(duration)\n",
    "        \n",
    "        to_plot = pd.concat([to_plot, pd.DataFrame({\n",
    "            \"layer\": [xbar_to_layer[xbar]],\n",
    "            \"xbar\": [str(xbar)], \n",
    "            \"start\": [start], \n",
    "            \"duration\": [duration], \n",
    "            \"done\": [done], \n",
    "            \"color\": [color_array[index % len(color_array)]],\n",
    "            \"text\": [f\"{duration:.2f} ms\"]\n",
    "            })])\n",
    "        \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x = to_plot[\"duration\"],\n",
    "    y = [to_plot[\"layer\"],\"xbar \" + to_plot[\"xbar\"]],\n",
    "    orientation = \"h\",\n",
    "    base = to_plot[\"start\"],\n",
    "    marker_color = to_plot[\"color\"],\n",
    "    # add text duration\n",
    "    text = to_plot[\"text\"],\n",
    ")\n",
    ")\n",
    "\n",
    "# change text font size\n",
    "\n",
    "# change size\n",
    "# fig.update_layout(\n",
    "#     autosize=False,\n",
    "#     width=2000,\n",
    "#     height=len(xbar_to_layer) * 30,\n",
    "#     margin=dict(l=0, r=0, t=0, b=0)\n",
    "# )\n",
    "\n",
    "# change x range\n",
    "fig.update_xaxes(range=[0, to_plot[\"start\"].max() * 1.1])\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'browser'\n",
    "# write jpg\n",
    "# fig.write_image(\"pip.jpg\", width=1920, height=1080, scale=2)\n",
    "fig.write_html(\"./pip.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "model = onnx.load(\"/home/pan251/accel-sim-framework-pim/resnet50.onnx\")\n",
    "\n",
    "with open(\"/home/pan251/accel-sim-framework-pim/serialized.model\", \"wb\") as f:\n",
    "  f.write(model.graph.SerializeToString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14.674277\n",
       "0    14.674275\n",
       "0    14.674275\n",
       "0    14.674275\n",
       "0    14.674275\n",
       "       ...    \n",
       "0    86.071648\n",
       "0    54.374099\n",
       "0    78.589089\n",
       "0    54.427327\n",
       "0    20.335157\n",
       "Name: duration, Length: 964, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_plot[\"duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation 0 (Linear) on layer 'embeddings'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 1 (Linear) on layer 'encoder.layer.0.attention.self.query'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 2 (Linear) on layer 'encoder.layer.0.attention.self.key'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 3 (MatMul) on layer 'encoder.layer.0.attention.self.value'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 64]), torch.Size([1, 12, 64, 15]))\n",
      "  Output shape: torch.Size([1, 12, 15, 15])\n",
      "Operation 4 (MatMul) on layer 'encoder.layer.0.attention.self.dropout'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 15]), torch.Size([1, 12, 15, 64]))\n",
      "  Output shape: torch.Size([1, 12, 15, 64])\n",
      "Operation 5 (Linear) on layer 'encoder.layer.0.attention.self'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 6 (Linear) on layer 'encoder.layer.0.attention'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([3072, 768]), torch.Size([3072]))\n",
      "  Output shape: torch.Size([1, 15, 3072])\n",
      "Operation 7 (Linear) on layer 'encoder.layer.0.intermediate'\n",
      "  Input shapes: (torch.Size([1, 15, 3072]), torch.Size([768, 3072]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 8 (Linear) on layer 'encoder.layer.0'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 9 (Linear) on layer 'encoder.layer.1.attention.self.query'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 10 (Linear) on layer 'encoder.layer.1.attention.self.key'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 11 (MatMul) on layer 'encoder.layer.1.attention.self.value'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 64]), torch.Size([1, 12, 64, 15]))\n",
      "  Output shape: torch.Size([1, 12, 15, 15])\n",
      "Operation 12 (MatMul) on layer 'encoder.layer.1.attention.self.dropout'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 15]), torch.Size([1, 12, 15, 64]))\n",
      "  Output shape: torch.Size([1, 12, 15, 64])\n",
      "Operation 13 (Linear) on layer 'encoder.layer.1.attention.self'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 14 (Linear) on layer 'encoder.layer.1.attention'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([3072, 768]), torch.Size([3072]))\n",
      "  Output shape: torch.Size([1, 15, 3072])\n",
      "Operation 15 (Linear) on layer 'encoder.layer.1.intermediate'\n",
      "  Input shapes: (torch.Size([1, 15, 3072]), torch.Size([768, 3072]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 16 (Linear) on layer 'encoder.layer.1'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 17 (Linear) on layer 'encoder.layer.2.attention.self.query'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 18 (Linear) on layer 'encoder.layer.2.attention.self.key'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 19 (MatMul) on layer 'encoder.layer.2.attention.self.value'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 64]), torch.Size([1, 12, 64, 15]))\n",
      "  Output shape: torch.Size([1, 12, 15, 15])\n",
      "Operation 20 (MatMul) on layer 'encoder.layer.2.attention.self.dropout'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 15]), torch.Size([1, 12, 15, 64]))\n",
      "  Output shape: torch.Size([1, 12, 15, 64])\n",
      "Operation 21 (Linear) on layer 'encoder.layer.2.attention.self'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 22 (Linear) on layer 'encoder.layer.2.attention'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([3072, 768]), torch.Size([3072]))\n",
      "  Output shape: torch.Size([1, 15, 3072])\n",
      "Operation 23 (Linear) on layer 'encoder.layer.2.intermediate'\n",
      "  Input shapes: (torch.Size([1, 15, 3072]), torch.Size([768, 3072]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 24 (Linear) on layer 'encoder.layer.2'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 25 (Linear) on layer 'encoder.layer.3.attention.self.query'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 26 (Linear) on layer 'encoder.layer.3.attention.self.key'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 27 (MatMul) on layer 'encoder.layer.3.attention.self.value'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 64]), torch.Size([1, 12, 64, 15]))\n",
      "  Output shape: torch.Size([1, 12, 15, 15])\n",
      "Operation 28 (MatMul) on layer 'encoder.layer.3.attention.self.dropout'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 15]), torch.Size([1, 12, 15, 64]))\n",
      "  Output shape: torch.Size([1, 12, 15, 64])\n",
      "Operation 29 (Linear) on layer 'encoder.layer.3.attention.self'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 30 (Linear) on layer 'encoder.layer.3.attention'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([3072, 768]), torch.Size([3072]))\n",
      "  Output shape: torch.Size([1, 15, 3072])\n",
      "Operation 31 (Linear) on layer 'encoder.layer.3.intermediate'\n",
      "  Input shapes: (torch.Size([1, 15, 3072]), torch.Size([768, 3072]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 32 (Linear) on layer 'encoder.layer.3'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 33 (Linear) on layer 'encoder.layer.4.attention.self.query'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 34 (Linear) on layer 'encoder.layer.4.attention.self.key'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 35 (MatMul) on layer 'encoder.layer.4.attention.self.value'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 64]), torch.Size([1, 12, 64, 15]))\n",
      "  Output shape: torch.Size([1, 12, 15, 15])\n",
      "Operation 36 (MatMul) on layer 'encoder.layer.4.attention.self.dropout'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 15]), torch.Size([1, 12, 15, 64]))\n",
      "  Output shape: torch.Size([1, 12, 15, 64])\n",
      "Operation 37 (Linear) on layer 'encoder.layer.4.attention.self'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 38 (Linear) on layer 'encoder.layer.4.attention'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([3072, 768]), torch.Size([3072]))\n",
      "  Output shape: torch.Size([1, 15, 3072])\n",
      "Operation 39 (Linear) on layer 'encoder.layer.4.intermediate'\n",
      "  Input shapes: (torch.Size([1, 15, 3072]), torch.Size([768, 3072]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 40 (Linear) on layer 'encoder.layer.4'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 41 (Linear) on layer 'encoder.layer.5.attention.self.query'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 42 (Linear) on layer 'encoder.layer.5.attention.self.key'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 43 (MatMul) on layer 'encoder.layer.5.attention.self.value'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 64]), torch.Size([1, 12, 64, 15]))\n",
      "  Output shape: torch.Size([1, 12, 15, 15])\n",
      "Operation 44 (MatMul) on layer 'encoder.layer.5.attention.self.dropout'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 15]), torch.Size([1, 12, 15, 64]))\n",
      "  Output shape: torch.Size([1, 12, 15, 64])\n",
      "Operation 45 (Linear) on layer 'encoder.layer.5.attention.self'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 46 (Linear) on layer 'encoder.layer.5.attention'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([3072, 768]), torch.Size([3072]))\n",
      "  Output shape: torch.Size([1, 15, 3072])\n",
      "Operation 47 (Linear) on layer 'encoder.layer.5.intermediate'\n",
      "  Input shapes: (torch.Size([1, 15, 3072]), torch.Size([768, 3072]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 48 (Linear) on layer 'encoder.layer.5'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 49 (Linear) on layer 'encoder.layer.6.attention.self.query'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 50 (Linear) on layer 'encoder.layer.6.attention.self.key'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 51 (MatMul) on layer 'encoder.layer.6.attention.self.value'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 64]), torch.Size([1, 12, 64, 15]))\n",
      "  Output shape: torch.Size([1, 12, 15, 15])\n",
      "Operation 52 (MatMul) on layer 'encoder.layer.6.attention.self.dropout'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 15]), torch.Size([1, 12, 15, 64]))\n",
      "  Output shape: torch.Size([1, 12, 15, 64])\n",
      "Operation 53 (Linear) on layer 'encoder.layer.6.attention.self'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 54 (Linear) on layer 'encoder.layer.6.attention'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([3072, 768]), torch.Size([3072]))\n",
      "  Output shape: torch.Size([1, 15, 3072])\n",
      "Operation 55 (Linear) on layer 'encoder.layer.6.intermediate'\n",
      "  Input shapes: (torch.Size([1, 15, 3072]), torch.Size([768, 3072]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 56 (Linear) on layer 'encoder.layer.6'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 57 (Linear) on layer 'encoder.layer.7.attention.self.query'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 58 (Linear) on layer 'encoder.layer.7.attention.self.key'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 59 (MatMul) on layer 'encoder.layer.7.attention.self.value'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 64]), torch.Size([1, 12, 64, 15]))\n",
      "  Output shape: torch.Size([1, 12, 15, 15])\n",
      "Operation 60 (MatMul) on layer 'encoder.layer.7.attention.self.dropout'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 15]), torch.Size([1, 12, 15, 64]))\n",
      "  Output shape: torch.Size([1, 12, 15, 64])\n",
      "Operation 61 (Linear) on layer 'encoder.layer.7.attention.self'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 62 (Linear) on layer 'encoder.layer.7.attention'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([3072, 768]), torch.Size([3072]))\n",
      "  Output shape: torch.Size([1, 15, 3072])\n",
      "Operation 63 (Linear) on layer 'encoder.layer.7.intermediate'\n",
      "  Input shapes: (torch.Size([1, 15, 3072]), torch.Size([768, 3072]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 64 (Linear) on layer 'encoder.layer.7'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 65 (Linear) on layer 'encoder.layer.8.attention.self.query'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 66 (Linear) on layer 'encoder.layer.8.attention.self.key'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 67 (MatMul) on layer 'encoder.layer.8.attention.self.value'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 64]), torch.Size([1, 12, 64, 15]))\n",
      "  Output shape: torch.Size([1, 12, 15, 15])\n",
      "Operation 68 (MatMul) on layer 'encoder.layer.8.attention.self.dropout'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 15]), torch.Size([1, 12, 15, 64]))\n",
      "  Output shape: torch.Size([1, 12, 15, 64])\n",
      "Operation 69 (Linear) on layer 'encoder.layer.8.attention.self'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 70 (Linear) on layer 'encoder.layer.8.attention'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([3072, 768]), torch.Size([3072]))\n",
      "  Output shape: torch.Size([1, 15, 3072])\n",
      "Operation 71 (Linear) on layer 'encoder.layer.8.intermediate'\n",
      "  Input shapes: (torch.Size([1, 15, 3072]), torch.Size([768, 3072]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 72 (Linear) on layer 'encoder.layer.8'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 73 (Linear) on layer 'encoder.layer.9.attention.self.query'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 74 (Linear) on layer 'encoder.layer.9.attention.self.key'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 75 (MatMul) on layer 'encoder.layer.9.attention.self.value'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 64]), torch.Size([1, 12, 64, 15]))\n",
      "  Output shape: torch.Size([1, 12, 15, 15])\n",
      "Operation 76 (MatMul) on layer 'encoder.layer.9.attention.self.dropout'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 15]), torch.Size([1, 12, 15, 64]))\n",
      "  Output shape: torch.Size([1, 12, 15, 64])\n",
      "Operation 77 (Linear) on layer 'encoder.layer.9.attention.self'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 78 (Linear) on layer 'encoder.layer.9.attention'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([3072, 768]), torch.Size([3072]))\n",
      "  Output shape: torch.Size([1, 15, 3072])\n",
      "Operation 79 (Linear) on layer 'encoder.layer.9.intermediate'\n",
      "  Input shapes: (torch.Size([1, 15, 3072]), torch.Size([768, 3072]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 80 (Linear) on layer 'encoder.layer.9'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 81 (Linear) on layer 'encoder.layer.10.attention.self.query'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 82 (Linear) on layer 'encoder.layer.10.attention.self.key'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 83 (MatMul) on layer 'encoder.layer.10.attention.self.value'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 64]), torch.Size([1, 12, 64, 15]))\n",
      "  Output shape: torch.Size([1, 12, 15, 15])\n",
      "Operation 84 (MatMul) on layer 'encoder.layer.10.attention.self.dropout'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 15]), torch.Size([1, 12, 15, 64]))\n",
      "  Output shape: torch.Size([1, 12, 15, 64])\n",
      "Operation 85 (Linear) on layer 'encoder.layer.10.attention.self'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 86 (Linear) on layer 'encoder.layer.10.attention'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([3072, 768]), torch.Size([3072]))\n",
      "  Output shape: torch.Size([1, 15, 3072])\n",
      "Operation 87 (Linear) on layer 'encoder.layer.10.intermediate'\n",
      "  Input shapes: (torch.Size([1, 15, 3072]), torch.Size([768, 3072]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 88 (Linear) on layer 'encoder.layer.10'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 89 (Linear) on layer 'encoder.layer.11.attention.self.query'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 90 (Linear) on layer 'encoder.layer.11.attention.self.key'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 91 (MatMul) on layer 'encoder.layer.11.attention.self.value'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 64]), torch.Size([1, 12, 64, 15]))\n",
      "  Output shape: torch.Size([1, 12, 15, 15])\n",
      "Operation 92 (MatMul) on layer 'encoder.layer.11.attention.self.dropout'\n",
      "  Input shapes: (torch.Size([1, 12, 15, 15]), torch.Size([1, 12, 15, 64]))\n",
      "  Output shape: torch.Size([1, 12, 15, 64])\n",
      "Operation 93 (Linear) on layer 'encoder.layer.11.attention.self'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 94 (Linear) on layer 'encoder.layer.11.attention'\n",
      "  Input shapes: (torch.Size([1, 15, 768]), torch.Size([3072, 768]), torch.Size([3072]))\n",
      "  Output shape: torch.Size([1, 15, 3072])\n",
      "Operation 95 (Linear) on layer 'encoder.layer.11.intermediate'\n",
      "  Input shapes: (torch.Size([1, 15, 3072]), torch.Size([768, 3072]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 15, 768])\n",
      "Operation 96 (Linear) on layer 'encoder'\n",
      "  Input shapes: (torch.Size([1, 768]), torch.Size([768, 768]), torch.Size([768]))\n",
      "  Output shape: torch.Size([1, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pan251/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# List to store operations\n",
    "operations = []\n",
    "\n",
    "# Save original functions\n",
    "original_matmul = torch.matmul\n",
    "original_linear = torch.nn.functional.linear\n",
    "\n",
    "# Monkey-patch torch.matmul\n",
    "def matmul_hook(input, other):\n",
    "    output = original_matmul(input, other)\n",
    "    operations.append({\n",
    "        'op_type': 'MatMul',\n",
    "        'input_ids': (id(input), id(other)),\n",
    "        'output_id': id(output),\n",
    "        'input_shapes': (input.shape, other.shape),\n",
    "        'output_shape': output.shape,\n",
    "        'layer_name': current_layer_name  # Add current layer name\n",
    "    })\n",
    "    return output\n",
    "\n",
    "torch.matmul = matmul_hook\n",
    "\n",
    "# Monkey-patch torch.nn.functional.linear\n",
    "def linear_hook(input, weight, bias=None):\n",
    "    output = original_linear(input, weight, bias)\n",
    "    operations.append({\n",
    "        'op_type': 'Linear',\n",
    "        'input_ids': (id(input), id(weight), id(bias) if bias is not None else None),\n",
    "        'output_id': id(output),\n",
    "        'input_shapes': (input.shape, weight.shape, bias.shape if bias is not None else None),\n",
    "        'output_shape': output.shape,\n",
    "        'layer_name': current_layer_name  # Add current layer name\n",
    "    })\n",
    "    return output\n",
    "\n",
    "torch.nn.functional.linear = linear_hook\n",
    "\n",
    "# Function to register forward hooks\n",
    "current_layer_name = None\n",
    "\n",
    "def forward_hook(layer_name):\n",
    "    def hook(module, input, output):\n",
    "        global current_layer_name\n",
    "        current_layer_name = layer_name  # Update the global variable to track the current layer name\n",
    "    return hook\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Register hooks on all layers\n",
    "for name, module in model.named_modules():\n",
    "    module.register_forward_hook(forward_hook(name))\n",
    "\n",
    "# Prepare sample input\n",
    "text = \"Hello, this is a sample input to test the BERT model.\"\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# Run the model\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Restore original functions\n",
    "torch.matmul = original_matmul\n",
    "torch.nn.functional.linear = original_linear\n",
    "\n",
    "# Build a mapping from output tensor IDs to operations\n",
    "tensor_id_to_op = {}\n",
    "for op in operations:\n",
    "    tensor_id_to_op[op['output_id']] = op\n",
    "\n",
    "# Assign operation IDs\n",
    "for idx, op in enumerate(operations):\n",
    "    op['op_id'] = idx\n",
    "\n",
    "# Build dependencies\n",
    "for op in operations:\n",
    "    op['depends_on'] = []\n",
    "    for input_id in op['input_ids']:\n",
    "        if input_id in tensor_id_to_op:\n",
    "            input_op = tensor_id_to_op[input_id]\n",
    "            op['depends_on'].append(input_op['op_id'])\n",
    "\n",
    "# Print the dependency graph\n",
    "for op in operations:\n",
    "    print(f\"Operation {op['op_id']} ({op['op_type']}) on layer '{op['layer_name']}'\")\n",
    "    print(f\"  Input shapes: {op['input_shapes']}\")\n",
    "    print(f\"  Output shape: {op['output_shape']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pan251/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bert_computation_graph.png'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Initialize BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Sample input text\n",
    "text = \"This is an example input for BERT.\"\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# Perform forward pass\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Visualize the computation graph\n",
    "# We take the last hidden state output for visualization\n",
    "graph = make_dot(outputs.last_hidden_state, params=dict(model.named_parameters()))\n",
    "\n",
    "# Render the graph and save it as a PNG image\n",
    "graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
